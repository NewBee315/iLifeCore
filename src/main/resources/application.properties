#jdbc driver
jdbc.driver=com.mysql.jdbc.Driver
jdbc.url = ${jdbc.url}
jdbc.username=${jdbc.username}
jdbc.password=${jdbc.password}

#kafka properties
#producer
#指定kafka节点列表，用于获取metadata
kafka.brokerlist=${kafka.brokerlist}
kafka.topic=${kafka.topic}
# producer刷新topic metada的时间间隔,producer需要知道partition leader的位置,以及当前topic的情况
# 因此producer需要一个机制来获取最新的metadata,当producer遇到特定错误时,将会立即刷新
# (比如topic失效,partition丢失,leader失效等),此外也可以通过此参数来配置额外的刷新机制，默认值600000
kafka.topic.metadata.refresh.interval.ms=600000
# 当producer接收到error ACK,或者没有接收到ACK时,允许消息重发的次数
# 因为broker并没有完整的机制来避免消息重复,所以当网络异常时(比如ACK丢失)
# 有可能导致broker接收到重复的消息,默认值为3.
kafka.message.send.max.retries=3
kafka.send.buffer.bytes=5242880
#consumer
kafka.consumer.timeout=1000
#指定消费组
kafka.group.id=${kafka.group.id}
kafka.max.messages=5000
# 如果zookeeper没有offset值或offset值超出范围。那么就给个初始的offset。有smallest、largest、
# anything可选，分别表示给当前最小的offset、当前最大的offset、抛异常。默认largest
kafka.auto.offset.reset=smallest
kafka.socket.receive.buffer.bytes=10485760
kafka.fetch.message.max.bytes=5242880
# 当consumer消费一定量的消息之后,将会自动向zookeeper提交offset信息
# 注意offset信息并不是每消费一次消息就向zk提交一次,而是现在本地保存(内存),并定期提交
# 自动更新时间。默认60 * 1000
kafka.auto.commit.interval.ms=1000
# zookeeper连接服务器地址，此处为线下测试环境配置(kafka消息服务-->kafka broker集群线上部署环境wiki)
kafka.zk.connect=${kafka.zk.connect}
# zookeeper的session过期时间，默认5000ms，用于检测消费者是否挂掉，当消费者挂掉，其他消费者要等该指定时间才能检查到并且触发重新负载均衡
kafka.zk.connection.timeout=6000
kafka.zk.session.timeout=6000
#当consumer reblance时，重试失败时时间间隔。
kafka.zk.sync.time=2000


